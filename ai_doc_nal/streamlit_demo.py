import os
import streamlit as st

from PIL import Image
from llama_index import (
    Document,
    GPTSimpleVectorIndex,
    GPTListIndex,
    LLMPredictor,
    ServiceContext,
    SimpleDirectoryReader,
    PromptHelper,
)
from llama_index.readers.file.base import DEFAULT_FILE_EXTRACTOR, ImageParser

from constants import DEFAULT_TERM_STR, DEFAULT_TERMS, REFINE_TEMPLATE, TEXT_QA_TEMPLATE
from utils import get_llm


if "all_terms" not in st.session_state:
    st.session_state["all_terms"] = DEFAULT_TERMS


@st.cache_resource
def get_file_extractor():
    image_parser = ImageParser(keep_image=True, parse_text=True)
    file_extractor = DEFAULT_FILE_EXTRACTOR
    file_extractor.update(
        {
            ".jpg": image_parser,
            ".png": image_parser,
            ".jpeg": image_parser,
            ".pdf": image_parser,
            ".txt": image_parser,
        }
    )

    return file_extractor


file_extractor = get_file_extractor()


def extract_terms(documents, term_extract_str, llm_name, model_temperature, api_key):
    llm = get_llm(llm_name, model_temperature, api_key, max_tokens=1024)

    service_context = ServiceContext.from_defaults(
        llm_predictor=LLMPredictor(llm=llm),
        prompt_helper=PromptHelper(
            max_input_size=4096, max_chunk_overlap=20, num_output=1024
        ),
        chunk_size_limit=1024,
    )

    temp_index = GPTListIndex.from_documents(documents, service_context=service_context)
    terms_definitions = str(
        temp_index.query(term_extract_str, response_mode="–¥–µ—Ä–µ–≤–æ_—Å—É–º–º–∏—Ä–æ–≤–∞–Ω–∏—è")
    )
    terms_definitions = [
        x
        for x in terms_definitions.split("\n")
        if x and "–°—Ä–æ–∫:" in x and "–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:" in x
    ]
    # —Ä–∞–∑–æ–±—Ä–∞—Ç—å —Ç–µ–∫—Å—Ç –Ω–∞ –¥–∏–∫—Ç—É
    terms_to_definition = {
        x.split("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")[0]
        .split("–°—Ä–æ–∫:")[-1]
        .strip(): x.split("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ:")[-1]
        .strip()
        for x in terms_definitions
    }
    return terms_to_definition
def read_directory(directory_path):
    """
     –ü—Ä–æ—á–∏—Ç–∞—Ç—å –≤—Å–µ —Ñ–∞–π–ª—ã –≤ –∫–∞—Ç–∞–ª–æ–≥–µ –∏ –ø–æ–¥–∫–∞—Ç–∞–ª–æ–≥–∞—Ö –∏ –∏–∑–≤–ª–µ—á—å –∏–∑ –Ω–∏—Ö —Ç–µ–∫—Å—Ç.

    Args:
        directory_path (str): Path to the directory.

    Returns:
        List[Document]: –°–ø–∏—Å–æ–∫ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤, –≥–¥–µ –∫–∞–∂–¥—ã–π –¥–æ–∫—É–º–µ–Ω—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É–µ—Ç —Ñ–∞–π–ª—É –≤ –∫–∞—Ç–∞–ª–æ–≥–µ..
    """
    documents = []
    for root, _, files in os.walk(directory_path):
        for file in files:
            file_path = os.path.join(root, file)
            file_extension = os.path.splitext(file_path)[1].lower()
            if file_extension in file_extractor:
                with open(file_path, "rb") as f:
                    content = f.read()
                    extracted = file_extractor[file_extension](content)
                    text = extracted.get("text", "")
                    if text.strip():
                        # create the directory "text/postoyanno" if it doesn't exist
                        os.makedirs("text/postoyanno", exist_ok=True)
                        # create the file name by appending ".txt" to the original file name
                        output_file_name = os.path.join("text/postoyanno", file.split(".")[0] + ".txt")
                        # write the extracted text to the output file
                        with open(output_file_name, "w", encoding="utf-8") as output_file:
                            output_file.write(text)
                        documents.append(Document(text))
    return documents



def insert_terms(terms_to_definition):
    for term, definition in terms_to_definition.items():
        doc = Document(f"–°—Ä–æ–∫: {term}\n–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ: {definition}")
        st.session_state["llama_index"].insert(doc)


@st.cache_resource
def initialize_index(llm_name, model_temperature, api_key):
    """–°–æ–∑–¥–∞–π—Ç–µ –æ–±—ä–µ–∫—Ç GPTSQLStructStoreIndex."""
    llm = get_llm(llm_name, model_temperature, api_key)

    service_context = ServiceContext.from_defaults(llm_predictor=LLMPredictor(llm=llm))

    index = GPTSimpleVectorIndex.load_from_disk(
        "./index.json", service_context=service_context
    )

    return index


st.title("–≠–∫—Å—Ç—Ä–∞–∫—Ç–æ—Ä —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏–Ω–¥–µ–∫—Å–∞ Llama ü¶ô")
st.markdown(
    (
        "–≠—Ç–∞ –ø—Ä–æ–≥—Ä–∞–º–º–∞ –ø–æ–∑–≤–æ–ª—è–µ—Ç –∑–∞–≥—Ä—É–∂–∞—Ç—å –≤–∞—à–∏ —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–µ –¥–æ–∫—É–º–µ–Ω—Ç—ã (–ª–∏–±–æ —Å–∫—Ä–∏–Ω—à–æ—Ç/–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ, –ª–∏–±–æ —Ä–µ–∞–ª—å–Ω—ã–π —Ç–µ–∫—Å—Ç) –∏ –∏–∑–≤–ª–µ–∫–∞—Ç—å —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è, —Å–æ–∑–¥–∞–≤–∞—è –±–∞–∑—É –∑–Ω–∞–Ω–∏–π."
    )
)

setup_tab, terms_tab, upload_tab, query_tab = st.tabs(
    ["–ù–∞—Å—Ç—Ä–æ–π–∫–∞", "–í—Å–µ —É—Å–ª–æ–≤–∏—è", "–£—Å–ª–æ–≤–∏—è –∑–∞–≥—Ä—É–∑–∫–∏/–∏–∑–≤–ª–µ—á–µ–Ω–∏—è", "–£—Å–ª–æ–≤–∏—è –∑–∞–ø—Ä–æ—Å–∞"]
)

with setup_tab:
    st.subheader("LLM –Ω–∞—Å—Ç—Ä–æ–π–∫–∞")
    api_key = st.text_input("–í–≤–µ–¥–∏—Ç–µ —Å–≤–æ–π –∫–ª—é—á API OpenAI –∑–¥–µ—Å—å", type="password")
    llm_name = st.selectbox(
        "–ö–∞–∫–∏–µ LLM?", ["text-davinci-003", "gpt-3.5-turbo", "gpt-4"]
    )
    model_temperature = st.slider(
        "–¢–µ–º–ø–µ—Ä–∞—Ç—É—Ä–∞ LLM", min_value=0.0, max_value=1.0, step=0.1
    )
    term_extract_str = st.text_area(
        "–ó–∞–ø—Ä–æ—Å –¥–ª—è –∏–∑–≤–ª–µ—á–µ–Ω–∏—è —Ç–µ—Ä–º–∏–Ω–æ–≤ –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π.", value=DEFAULT_TERM_STR
    )
    directory_path = st.text_input("–í–≤–µ–¥–∏—Ç–µ –ø—É—Ç—å –∫ –ø–∞–ø–∫–µ –¥–ª—è —á—Ç–µ–Ω–∏—è —Ñ–∞–π–ª–æ–≤")

    if st.button("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ –∏ —Å–±—Ä–æ—Å —É—Å–ª–æ–≤–∏–π", key="init_index"):
        st.session_state["llama_index"] = initialize_index(
            llm_name, model_temperature, api_key
        )
        st.session_state["all_terms"] = DEFAULT_TERMS

        if directory_path:
            documents = read_directory(directory_path)
            st.session_state["llama_index"].insert(*documents)



with terms_tab:
    st.subheader("–¢–µ–∫—É—â–∏–µ –∏–∑–≤–ª–µ—á–µ–Ω–Ω—ã–µ —Ç–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è")
    st.json(st.session_state["all_terms"])


with upload_tab:
    st.subheader("–û–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –∏–∑–≤–ª–µ—á–µ–Ω–∏–π –∏ –∑–∞–ø—Ä–æ—Å–æ–≤")
    if st.button("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ –∏ —Å–±—Ä–æ—Å —É—Å–ª–æ–≤–∏–π", key="init_index_1"):
        st.session_state["llama_index"] = initialize_index(
            llm_name, model_temperature, api_key
        )
        st.session_state["all_terms"] = DEFAULT_TERMS

    if "llama_index" in st.session_state:
        st.markdown(
            "–õ–∏–±–æ –∑–∞–≥—Ä—É–∑–∏—Ç–µ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/—Å–∫—Ä–∏–Ω—à–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞, –ª–∏–±–æ –≤–≤–µ–¥–∏—Ç–µ —Ç–µ–∫—Å—Ç –≤—Ä—É—á–Ω—É—é."
        )
        uploaded_file = st.file_uploader(
            "–ó–∞–≥—Ä—É–∑–∏—Ç—å –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏–µ/—Å–∫—Ä–∏–Ω—à–æ—Ç –¥–æ–∫—É–º–µ–Ω—Ç–∞:", type=["png", "jpg", "jpeg"]
        )
        document_text = st.text_area("–ò–ª–∏ –≤–≤–µ–¥–∏—Ç–µ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã–π —Ç–µ–∫—Å—Ç")
        if st.button("–¢–µ—Ä–º–∏–Ω—ã –∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è —ç–∫—Å—Ç—Ä–∞–∫—Ç–∞") and (
            uploaded_file or document_text
        ):
            st.session_state["—É—Å–ª–æ–≤–∏—è"] = {}
            terms_docs = {}
            with st.spinner("–ò–∑–≤–ª–µ—á–µ–Ω–∏–µ (–∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è –º–æ–≥—É—Ç –±—ã—Ç—å –º–µ–¥–ª–µ–Ω–Ω—ã–º–∏)..."):
                if document_text:
                    terms_docs.update(
                        extract_terms(
                            [Document(document_text)],
                            term_extract_str,
                            llm_name,
                            model_temperature,
                            api_key,
                        )
                    )
                if uploaded_file:
                    Image.open(uploaded_file).convert("RGB").save("temp.png")
                    img_reader = SimpleDirectoryReader(
                        input_files=["temp.png"], file_extractor=file_extractor
                    )
                    img_docs = img_reader.load_data()
                    os.remove("temp.png")
                    terms_docs.update(
                        extract_terms(
                            img_docs,
                            term_extract_str,
                            llm_name,
                            model_temperature,
                            api_key,
                        )
                    )
            st.session_state["—É—Å–ª–æ–≤–∏—è"].update(terms_docs)

    if "—É—Å–ª–æ–≤–∏—è" in st.session_state and st.session_state["—É—Å–ª–æ–≤–∏—è"]:
        st.markdown("Extracted terms")
        st.json(st.session_state["—É—Å–ª–æ–≤–∏—è"])

        if st.button("Insert terms?"):
            with st.spinner("Inserting terms"):
                insert_terms(st.session_state["—É—Å–ª–æ–≤–∏—è"])
            st.session_state["all_terms"].update(st.session_state["—É—Å–ª–æ–≤–∏—è"])
            st.session_state["—É—Å–ª–æ–≤–∏—è"] = {}
            st.experimental_rerun()

with query_tab:
    st.subheader("–ó–∞–ø—Ä–æ—Å —Ç–µ—Ä–º–∏–Ω–æ–≤/–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–π!")
    st.markdown(
        (
            "LLM –ø–æ–ø—ã—Ç–∞–µ—Ç—Å—è –æ—Ç–≤–µ—Ç–∏—Ç—å –Ω–∞ –≤–∞—à –∑–∞–ø—Ä–æ—Å –∏ –¥–æ–ø–æ–ª–Ω–∏—Ç —Å–≤–æ–∏ –æ—Ç–≤–µ—Ç—ã, –∏—Å–ø–æ–ª—å–∑—É—è –≤–≤–µ–¥–µ–Ω–Ω—ã–µ –≤–∞–º–∏ —Ç–µ—Ä–º–∏–Ω—ã/–æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è. "
            "–ï—Å–ª–∏ —Ç–µ—Ä–º–∏–Ω–∞ –Ω–µ—Ç –≤ –∏–Ω–¥–µ–∫—Å–µ, –æ–Ω –æ—Ç–≤–µ—Ç–∏—Ç, –∏—Å–ø–æ–ª—å–∑—É—è —Å–≤–æ–∏ –≤–Ω—É—Ç—Ä–µ–Ω–Ω–∏–µ –∑–Ω–∞–Ω–∏—è"
        )
    )
    if st.button("–ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –∏–Ω–¥–µ–∫—Å–∞ –∏ —Å–±—Ä–æ—Å —É—Å–ª–æ–≤–∏–π", key="init_index_2"):
        st.session_state["llama_index"] = initialize_index(
            llm_name, model_temperature, api_key
        )
        st.session_state["all_terms"] = DEFAULT_TERMS

    if "llama_index" in st.session_state:
        query_text = st.text_input("–°–ø—Ä–æ—Å–∏—Ç–µ –æ —Ç–µ—Ä–º–∏–Ω–µ –∏–ª–∏ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–∏:")
        if query_text:
            with st.spinner("–ì–µ–Ω–µ—Ä–∞—Ü–∏—è –æ—Ç–≤–µ—Ç–∞..."):
                response = st.session_state["llama_index"].query(
                    query_text, similarity_top_k=5, response_mode="compact",
                    text_qa_template=TEXT_QA_TEMPLATE, refine_template=REFINE_TEMPLATE
                )
            st.markdown(str(response))
